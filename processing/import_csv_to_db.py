# üìÅ processing/import_csv_to_db.py

import pandas as pd
from pathlib import Path
from sqlalchemy.exc import IntegrityError
from database.db_loader import DBConnector, Source
from datetime import datetime
import logging

class CSVtoDatabaseLoader:
    """Bezpeƒçn√Ω import CSV dat do datab√°ze s validac√≠ a logov√°n√≠m"""

    def __init__(self):
        self.db = DBConnector()
        self.session = self.db.Session()
        self.setup_logging()

    def setup_logging(self):
        """Nastaven√≠ logov√°n√≠ pro sledov√°n√≠ importu"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('import_log.txt'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def validate_row(self, row, csv_path):
        """Validace jednotliv√Ωch ≈ô√°dk≈Ø dat"""
        errors = []
        
        # Kontrola pr√°zdn√Ωch hodnot
        if not row.get("url"):
            errors.append("Chyb√≠ URL")
        if not row.get("title"):
            errors.append("Chyb√≠ titulek")
        if not row.get("text") or len(str(row.get("text", "")).strip()) < 10:
            errors.append("Chyb√≠ nebo p≈ô√≠li≈° kr√°tk√Ω text")
            
        # Validace URL
        if row.get("url") and not row["url"].startswith(("http://", "https://")):
            errors.append("Neplatn√© URL")
            
        # Validace data
        try:
            pd.to_datetime(row.get("scraped_at"))
        except:
            errors.append("Neplatn√© datum")
            
        if errors:
            self.logger.warning(f"Validaƒçn√≠ chyby v {csv_path}: {', '.join(errors)}")
            return False
        return True

    def clean_row(self, row):
        """ƒåi≈°tƒõn√≠ a normalizace dat"""
        return {
            "movement_id": None,  # bude doplnƒõno pozdƒõji
            "source_name": str(row.get("source_name", "")).strip(),
            "source_type": str(row.get("source_type", "")).strip(),
            "publication_date": pd.to_datetime(row.get("scraped_at"), errors="coerce"),
            "sentiment_rating": None,  # bude doplnƒõno p≈ôi NLP
            "url": str(row.get("url", "")).strip(),
            "title": str(row.get("title", "")).strip(),
            "text": str(row.get("text", "")).strip()
        }

    def load_csv_to_sources(self, csv_path: str):
        """Import CSV do datab√°ze s validac√≠ a error handlingem"""
        csv_path = Path(csv_path)
        if not csv_path.exists():
            self.logger.error(f"Soubor neexistuje: {csv_path}")
            return

        try:
            df = pd.read_csv(csv_path)
            self.logger.info(f"Naƒç√≠t√°m {len(df)} ≈ô√°dk≈Ø z {csv_path}")

            # Kontrola po≈æadovan√Ωch sloupc≈Ø
            required_columns = {"source_name", "source_type", "title", "url", "text", "scraped_at"}
            if not required_columns.issubset(df.columns):
                missing = required_columns - set(df.columns)
                raise ValueError(f"Chyb√≠ sloupce: {missing}")

            # Import po batches pro lep≈°√≠ v√Ωkon a mo≈ænost rollbacku
            batch_size = 100
            imported = 0
            skipped = 0

            for batch_start in range(0, len(df), batch_size):
                batch = df.iloc[batch_start:batch_start + batch_size]
                
                for _, row in batch.iterrows():
                    try:
                        # Validace a ƒçi≈°tƒõn√≠
                        if not self.validate_row(row, csv_path):
                            skipped += 1
                            continue
                            
                        cleaned_data = self.clean_row(row)
                        source = Source(**cleaned_data)
                        self.session.add(source)
                        imported += 1
                        
                    except Exception as e:
                        self.logger.error(f"Chyba p≈ôi zpracov√°n√≠ ≈ô√°dku: {e}")
                        skipped += 1
                        continue
                
                try:
                    self.session.commit()
                except IntegrityError:
                    self.session.rollback()
                    self.logger.warning("Duplicitn√≠ URL - p≈ôeskakuji batch")
                    skipped += len(batch)
                except Exception as e:
                    self.session.rollback()
                    self.logger.error(f"Chyba p≈ôi ukl√°d√°n√≠ batch: {e}")
                    skipped += len(batch)

            self.logger.info(f"Import dokonƒçen: {imported} importov√°no, {skipped} p≈ôeskoƒçeno")
        except IntegrityError:
            self.session.rollback()
            print("‚ö†Ô∏è Duplicitn√≠ URL ‚Äì nƒõkter√© z√°znamy ji≈æ existuj√≠.")
        except Exception as e:
            self.session.rollback()
            print(f"‚ùå Chyba p≈ôi naƒç√≠t√°n√≠ CSV: {e}")
        finally:
            self.session.close()
