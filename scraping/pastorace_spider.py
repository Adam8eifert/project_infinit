# üìÅ scraping/pastorace_spider.py
# Scrapy spider pro pastorace.cz ‚Äì kategorie Sekty a kulty

import scrapy
import datetime

class PastoraceSpider(scrapy.Spider):
    name = "pastorace"
    allowed_domains = ["pastorace.cz"]
    start_urls = ["https://www.pastorace.cz/Clanky/Nabozenstvi/Sekty-a-kulty"]

    custom_settings = {
        "FEEDS": {
            "export/csv/pastorace_raw.csv": {
                "format": "csv",
                "overwrite": True,
                "encoding": "utf8",
            }
        },
        "LOG_LEVEL": "INFO"
    }

    keywords = [
        "sekta", "nov√© n√°bo≈æensk√© hnut√≠", "nov√° n√°bo≈æensk√° hnut√≠",
        "nov√© duchovn√≠ hnut√≠", "nov√° duchovn√≠ hnut√≠",
        "n√°bo≈æensk√° skupina", "n√°bo≈æensk√° komunita",
        "alternativn√≠ n√°bo≈æenstv√≠", "kontroverzn√≠ n√°bo≈æensk√° spoleƒçnost",
        "destruktivn√≠ kult", "kult", "nov√© spiritu√°ln√≠ hnut√≠"
    ]

    def parse(self, response):
        links = response.css(".list-articles a::attr(href)").getall()
        for href in links:
            full_url = response.urljoin(href)
            yield response.follow(full_url, callback=self.parse_article)

    def parse_article(self, response):
        title = response.css("h1::text").get()
        content = response.css("div.article *::text").getall()
        full_text = " ".join([t.strip() for t in content if t.strip()])

        yield {
            "source_name": "pastorace.cz",
            "source_type": "web",
            "title": title,
            "url": response.url,
            "text": full_text,
            "scraped_at": datetime.datetime.now().isoformat()
        }
