# ğŸ“ scraping/wikipedia_spider.py â€“ Wikipedia API mÃ­sto scrappingu

import scrapy
import datetime
import json
from urllib.parse import urlencode

class WikipediaSpider(scrapy.Spider):
    name = "wikipedia"
    allowed_domains = ["cs.wikipedia.org"]

    custom_settings = {
        "FEEDS": {
            "export/csv/wikipedia_raw.csv": {
                "format": "csv",
                "overwrite": True,
                "encoding": "utf8"
            }
        },
        "LOG_LEVEL": "INFO"
    }

    def start_requests(self):
        params = {
            "action": "parse",
            "page": "Seznam_cÃ­rkvÃ­_a_nÃ¡boÅ¾enskÃ½ch_spoleÄnostÃ­_v_ÄŒesku",
            "format": "json",
            "prop": "wikitext",
            "formatversion": 2
        }
        url = f"https://cs.wikipedia.org/w/api.php?{urlencode(params)}"
        yield scrapy.Request(url, callback=self.parse_api)

    def parse_api(self, response):
        data = json.loads(response.text)
        wikitext = data.get("parse", {}).get("wikitext", "")

        # velmi jednoduchÃ½ extraktor â€“ spolehÃ¡ se na formÃ¡t seznamu s hvÄ›zdiÄkami
        lines = wikitext.split("\n")
        for line in lines:
            if line.startswith("*"):
                name = line.lstrip("* ").strip()
                if name:
                    yield {
                        "source_name": "Wikipedia",
                        "source_type": "encyklopedie",
                        "title": name,
                        "url": "https://cs.wikipedia.org/wiki/Seznam_cÃ­rkvÃ­_a_nÃ¡boÅ¾enskÃ½ch_spoleÄnostÃ­_v_ÄŒesku",
                        "text": "",
                        "scraped_at": datetime.datetime.now().isoformat()
                    }
